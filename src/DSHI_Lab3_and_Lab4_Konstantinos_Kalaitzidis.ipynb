{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafdccdd-c444-4834-b56b-41d4cde40627",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 3 Classification Models & Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95d8cd9-a988-4c11-ad1d-f45400aa25f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Thu Sep  01 15:40:00 2022\\n\\n@author: konstantinoskalaitzidis\\nstudent_name =   \"Konstantinos Kalaitzidis\"\\nstudent_email =  \"kon.kalaitzidis@gmail.com\"\\n\\nNotebook based on notes from Christian Kauth (UniFribourg) and Maria Bampa (DSV)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep  01 15:40:00 2022\n",
    "\n",
    "@author: konstantinoskalaitzidis\n",
    "student_name =   \"Konstantinos Kalaitzidis\"\n",
    "student_email =  \"kon.kalaitzidis@gmail.com\"\n",
    "\n",
    "Notebook based on notes from Christian Kauth (UniFribourg) and Maria Bampa (DSV)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce48a4f-7442-4a41-ae0e-966d46b4c88d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This is the 3rd and 4th lab exercise of the Data Science for Health Informatics (DSHI) module of Stockholm University (2022). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842235bb-2f53-4bd5-85f1-815059bf5820",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059118b5-d9dc-4198-95e3-3cfa838ced1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package with an alias\n",
    "# Numeric analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbeaed8-401e-43bd-896e-a674fd9d3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed of the pseudo randomization to guarantee that results are reproducible between executions\n",
    "RANDOM_SEED = 3456\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcffb0e-3313-4879-974a-a6e2c350435b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introductory information:\n",
    "Applying 3 classification models on our dataset that perform on 2 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a35f78-f0e3-49a1-84f4-61d71610d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/konstantinoskalaitzidis/Desktop/DSHI/Data-Analysis/avocado.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3325af-3c9c-4b91-a8c8-6a41a3b57cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to pickle file\n",
    "df.to_pickle('avocado1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9938aa-7ac0-4128-885a-4e03fdafa576",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bcb089-a198-4e07-baf3-0d8ddf7d8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18249, 14)\n"
     ]
    }
   ],
   "source": [
    "# read pickle file as dataframe\n",
    "df = pd.read_pickle('avocado1.pkl')\n",
    "# display the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f99c5-a852-43e8-82f7-4656ebb631e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18249, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the total size of the dataset?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15f394-1b84-451e-8e6a-8af12b5fd031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "Date             object\n",
       "AveragePrice    float64\n",
       "Total Volume    float64\n",
       "4046            float64\n",
       "4225            float64\n",
       "4770            float64\n",
       "Total Bags      float64\n",
       "Small Bags      float64\n",
       "Large Bags      float64\n",
       "XLarge Bags     float64\n",
       "type             object\n",
       "year              int64\n",
       "region           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which are the variable types?\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a437a-e06d-425c-bf8e-d74f9c2eb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the first three rows of our dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01454ca6-da66-41ec-85ec-255fc3c39af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at three random rows of our dataset\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab625d35-83b5-4d36-a024-d713e86c89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at the last three rows of our dataset\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6556841-af9d-4800-b0d4-aab82fdc16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read some information about our dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492745ef-d514-445a-91c4-114e68771e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79fd2b-eefc-4432-88d7-4da8551d4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2bbb1-3f45-4956-892b-798e6ef30559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to verify that no null data is present in the dataframe is to check if the red \n",
    "# color in the plot is distributed equally according to each colunm.'''\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e1994-ce10-40bf-a7dc-e183884af9a1",
   "metadata": {},
   "source": [
    "Great. No missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526df93-a6df-4dfa-af3f-a9d17149609f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b248490-8a7c-422f-83cc-6c49a3a1b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting irrelevant features\n",
    "columns_to_delete = [\"Unnamed: 0\"]\n",
    "\n",
    "# axis=1 means that the operation is executed in the columns, axis=0 is in the rows\n",
    "df = df.drop(columns_to_delete, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b2350-af17-4ad0-9843-26cfecca9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6388b08-2d66-47f1-a465-3222e4ad2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b8e6f-fa67-49d6-ad48-a8da029dddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a80dc-cf18-4727-a709-ec014b852add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to change the Date from an Object type to a Date type\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "df['Month']=df['Date'].apply(lambda x:x.month)\n",
    "df['Day']=df['Date'].apply(lambda x:x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c6e10-41be-4324-8474-bb7682236ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff00e8-82c7-416f-872c-424ce7466f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to change the data types of \"type\" and \"region\" and make them categorical. \n",
    "df[\"type\"] = df[\"type\"].astype(\"category\")\n",
    "df[\"region\"] = df[\"region\"].astype(\"category\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4530c-bb08-4503-8ded-4b27986aabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describes the numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ecb7f-6742-400a-aa08-cb7af4fde03d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Store processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca252a-808d-4d22-bf77-c848a3e48f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "this_path = \".\"\n",
    "folder_name = \"data\"\n",
    "data_folder = os.path.join(this_path, folder_name)\n",
    "os.makedirs(data_folder, exist_ok=True) # Check if the folder exists\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59e024-3957-4472-9c55-4870ae52c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"avocado_processed.csv\"\n",
    "filepath = os.path.join(data_folder, file_name)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0e0d-5df9-4059-b46f-dd011bea7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565aeeb-7ebf-4a6f-aa21-e0ebc0fcf13d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde7068-e16d-46fe-9195-f13e321f758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the representatitve average price range?\n",
    "sns.set(font_scale=1.5) \n",
    "from scipy.stats import norm\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(a=df.AveragePrice, kde=False, fit=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa7f84-28a7-490a-8058-d790021043d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price distribution between conventional and oranic avocados. \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=\"Month\", y=\"AveragePrice\", hue='type', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de6413-a4fc-49e4-b34b-48a9e2012905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price distribution over date\n",
    "byDate=df.groupby('Date').mean()\n",
    "plt.figure(figsize=(12,6))\n",
    "byDate['AveragePrice'].plot()\n",
    "plt.title('Average Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf74e5-dffd-433d-aaf9-b6384bf03d2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645f153-7c4e-4525-97e2-666aed85b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corr(method=\"pearson\")\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043a0ae-247a-4687-86a3-6c779b1bc939",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e0478-5326-4c53-8fe4-757c8b0f857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d1ec7-16bc-4f42-97c0-c6b706e6cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting irrelevant features\n",
    "columns_to_delete = [\"Date\", \"region\"]\n",
    "\n",
    "# axis=1 means that the operation is executed in the columns, axis=0 is in the rows\n",
    "df = df.drop(columns_to_delete, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534df0ee-d17c-40f8-8bb9-637f1c806e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279a5d-c2f2-4d24-9956-1a423c0b14c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "For categorical values \"type\" we apply what is called **one-hot encoding**, when each possible value in the categorical feature is transformed into a column and populated with 1s and 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9f671-aef8-4563-87dd-56862ed3df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function transforms a categorical feature into one-hot encoding\n",
    "pd.get_dummies(df[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfb193-8cfe-466c-bc8f-e204923a663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the column in the dataframe \n",
    "# Add the new columns after one-hot encoding\n",
    "oh_encoding = pd.get_dummies(df[\"type\"])\n",
    "df = pd.concat([df, oh_encoding], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb41897-744b-42e9-a48e-0d4d0da8dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d79ca-80a3-4507-8bb4-edc1f1e5a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e897a-d0c1-474f-a5d3-21acf1542d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"] = df[\"type\"].map({\n",
    "                \"conventional\":0, \n",
    "                \"organic\":1\n",
    "            })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb033a9-2895-4609-9ba6-4dfd16804111",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Normalization & Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad26e59-0f11-4713-90a5-146414b16d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset has more than 200 rows I need to find a sample of it which I will use.\n",
    "df = df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b856fd4-9f42-4115-aa42-605edb6257c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88de48b-5d67-46ab-8142-a60982ff5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bd384-646f-4f64-a8c3-0a6279bdc5a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa72d7f-a573-4e8c-a385-f3402d2f985b",
   "metadata": {},
   "source": [
    "We have chosen 2 numerical features that are relatable to the target variable that we intend to predict. We are only training datasets with two features to simplify the visualization of the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb554ad-f1bd-4c73-98ba-39aedf0d08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({\n",
    "                        \"x1\": df.iloc[:, 0],\n",
    "                        \"x2\": df.iloc[:, 1],\n",
    "                        \"class\": df.iloc[:, 9]\n",
    "                        })\n",
    "df_new.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd2e01-293b-4424-a3bc-fe9f64d49ae9",
   "metadata": {},
   "source": [
    "Filtering the original dataset to create two arrays that contain only feature matrix ( ùëã ) and target label array ( ùë¶ )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f322170-7ae4-481c-ad91-db2479d8caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:,:2] # features x1 and x2\n",
    "y = df_new.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffbca8-77ea-4fdd-9111-7bfb954d0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2d6ae-c94f-495d-991e-0aaa96e85bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06996839-3cab-4cdf-89ba-68d6845b53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee311d-69f3-4abd-88e1-108469d21823",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2b2e7-214e-4461-b11f-279d04540a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045416b-3ef2-4be3-9c15-860471770a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to see the dataset easier\n",
    "def visualize_dataset_with_target_class(X, y, title=\"\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: (np.array[N,2]) - The features from the data\n",
    "        y: (np.array[N,1]) - The corresponding target class of each sample\n",
    "    Returns:\n",
    "        A plot with the dataset and the colors of the respective class\n",
    "    \"\"\"\n",
    "    plt.scatter(x = X.iloc[:,0], y = X.iloc[:,1], c=y, s=30)\n",
    "    plt.xlabel(\"Average Price\")\n",
    "    plt.ylabel(\"Total Volume\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    return plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd4911-af8e-45ce-a45e-3328be7a0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset_with_target_class(X, y, title=\"Dataset with original class labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c0d94-1ce7-4193-8bfc-e99835c2ce6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train-test partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bfdb6-2894-48f4-b126-630f632ee5c2",
   "metadata": {},
   "source": [
    "Perform train-test split with a proportion of 80%/20%.\n",
    "We want our target variable to not be continuous e.g. average price. \n",
    "Synthetic data is in X variable\n",
    "y label to train the model\n",
    "class = type\n",
    "X1 = average price\n",
    "X2 = total volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa4092-1972-4d37-b414-2d23da5dd3ef",
   "metadata": {},
   "source": [
    "X and y must have the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947cb34-c8ac-4ab3-ac54-82578e1e20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017fcb8-c631-4413-b263-314a10418cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TRAINING set\n",
    "visualize_dataset_with_target_class(X_train, y_train, title=\"Training set with original class labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f678619-6c93-4afb-977f-7814c0b09944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TEST set \n",
    "visualize_dataset_with_target_class(X_test, y_test, title=\"Test set with original class labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c290c-035b-4add-8f7a-80cc8f23f171",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f7ecb-d9b6-42dc-9a5e-e77a594d6649",
   "metadata": {},
   "source": [
    "We will train three classifiers on our small dataset: A decision tree (DT), a random forest (RF), and a K-nearest neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cda81f-c69a-473b-a0b5-79998e4cb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa1a37-3515-4b6f-b39e-901353987512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42fb84-35c0-4a92-8c77-1543f24ba719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we start our counter\n",
    "t_start = time.time()\n",
    "\n",
    "# Recall from the previous lab that these are the traditional three steps for most sklearn models.\n",
    "\n",
    "# 1) Initialize an object containing the algorithm\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=6)     # Criterion split by default is gini-index, which is ok\n",
    "\n",
    "# 2) Apply the algorithm using the training data\n",
    "dt_classifier.fit(X_train, y_train)   ### NOTE here that we also used the labels `y`, in clustering algorithms we only pass `X`\n",
    "\n",
    "# 3) Generate class labels for new unseen data (predictions)\n",
    "y_predicted = dt_classifier.predict(X_test)\n",
    "\n",
    "print(\"According to the DT classifier, the class labels in the test set are: \", y_predicted)\n",
    "# At the end we calculate the end time\n",
    "t_end = time.time()\n",
    "t_elapsed = t_end - t_start\n",
    "\n",
    "print(f\"The elapsed time of the function is {t_elapsed} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41aa3e1-bd60-4cc6-bb01-8f92ec49a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to visualize the true labels and predicted labels easier\n",
    "def visualize_and_compare_classifications(X, real_y, predicted_y, title=\"\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: (np.array[N,2]) - The dataset to visualize (only 2 features)\n",
    "        real_y: (np.array[N,1]) - Real class labels from X\n",
    "        predicted_y: (np.array[N,1]) - Predicted class labels from X\n",
    "    Returns:\n",
    "        A plot with two axes showing the real and the predicted labels\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "    \n",
    "    # First plot contains real class labels\n",
    "    ax = axes[0]\n",
    "    ax.scatter(x = X.iloc[:,0], y = X.iloc[:,1], c=real_y, s=80)\n",
    "    ax.set(xlabel=\"Average Price\",ylabel=\"Total Volume\",title=\"Real labels\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Second plot contains predicted class labels\n",
    "    ax = axes[1]\n",
    "    ax.scatter(x = X.iloc[:,0], y = X.iloc[:,1], c=predicted_y, s=80)\n",
    "    ax.set(xlabel=\"Average Price\",ylabel=\"Total Volume\",title=\"Predicted labels\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    if title is not \"\":\n",
    "        plt.suptitle(title)\n",
    "\n",
    "    return plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce51bf8-a2fb-4a2e-bcf9-f30a1e64bb28",
   "metadata": {},
   "source": [
    "Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70004a8d-70fb-4a67-8abd-e4f65a5b66ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_and_compare_classifications(X_test, y_test, y_predicted, title=\"Real and predicted classes for the test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90286fbe-2791-4ce7-9486-d01bf5022b08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8face54c-4dc1-4109-8797-daf36702fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn also has functions to visualize the Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(dt_classifier.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e479a-5813-431a-b00d-7e634d2d0d5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09069653-a214-488d-a08c-8bc68f9fe78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "t_start = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, max_depth=3, criterion=\"entropy\")\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_predicted = rf_classifier.predict(X_test)\n",
    "\n",
    "print(\"According to the RF classifier, the class labels in the test set are: \", y_predicted)\n",
    "\n",
    "# At the end we calculate the end time\n",
    "t_end = time.time()\n",
    "t_elapsed = t_end - t_start\n",
    "\n",
    "print(f\"The elapsed time of the function is {t_elapsed} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a437658-c4fa-4f98-bb1d-ce58403c56bf",
   "metadata": {},
   "source": [
    "Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afe60e-f199-4458-8279-db63884dc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_compare_classifications(X_test, y_test, y_predicted, title=\"Real and predicted classes for the test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ff4d7-7a4a-439f-a5cd-6201f42d3c4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K-nearest neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e79643-d802-411b-adb8-5ccbcddd6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data for KNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "norm_X_train = scaler.fit_transform(X_train)\n",
    "norm_X_test  = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df6fbb-699b-433e-9864-37d88f316218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)    # The default distance metric is Euclidean, which is usually ok.\n",
    "knn_classifier.fit(norm_X_train, y_train)\n",
    "y_predicted = knn_classifier.predict(norm_X_test)\n",
    "\n",
    "# At the end we calculate the end time\n",
    "t_end = time.time()\n",
    "t_elapsed = t_end - t_start\n",
    "\n",
    "print(f\"The elapsed time of the function is {t_elapsed} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e09281-d59c-4ebe-be93-f3c0cbea838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to visualize the true labels and predicted labels easier\n",
    "def visualize_and_compare_classifications_version2(X, real_y, predicted_y, title=\"\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: (np.array[N,2]) - The dataset to visualize (only 2 features)\n",
    "        real_y: (np.array[N,1]) - Real class labels from X\n",
    "        predicted_y: (np.array[N,1]) - Predicted class labels from X\n",
    "    Returns:\n",
    "        A plot with two axes showing the real and the predicted labels\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "    \n",
    "    # First plot contains real class labels\n",
    "    ax = axes[0]\n",
    "    ax.scatter(x = X[:,0], y = X[:,1], c=real_y, s=80)\n",
    "    ax.set(xlabel=\"Average Price\",ylabel=\"Total Volume\",title=\"Real labels\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Second plot contains predicted class labels\n",
    "    ax = axes[1]\n",
    "    ax.scatter(x = X[:,0], y = X[:,1], c=predicted_y, s=80)\n",
    "    ax.set(xlabel=\"Average Price\",ylabel=\"Total Volume\",title=\"Predicted labels\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    if title is not \"\":\n",
    "        plt.suptitle(title)\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146348d0-af4b-4962-9bba-644e19428d53",
   "metadata": {},
   "source": [
    "Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fcbb24-5f23-4183-b209-db429bf9e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_compare_classifications_version2(norm_X_test, y_test, y_predicted, title=\"Real and predicted classes for the test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a374f-33fb-49dc-96e0-dd601bb004e5",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702eea9-5a0c-4e8e-a74f-38d2ac8ebbee",
   "metadata": {},
   "source": [
    "We applied 3 classification models on our dataset that performed on the 2-features that we selected. For each classifier, we showed a plot of the predicted classification.\n",
    "\n",
    "There is a noticeable difference between the performance of the\n",
    "KNN classifier compared to the RF and DT. The KNN classifier is much faster whereas the\n",
    "RF and DT are closer to each other, performance-wise. For the features, we chose Average\n",
    "Price and Total Volume and created an X variable that contains both so I can feed them into\n",
    "the classifiers. In place for y, we used the ‚Äútype‚Äù target variable (organic or conventional)\n",
    "which takes numerical values (0 or 1 respectively) and has been previously one-hot encoded.\n",
    "\n",
    "When looking at the plots, we can clearly see an outlier which can be removed\n",
    "in future work. Other than that, the plots look very similar to each other with minor\n",
    "differences in the labels between the Real and Predicted labels plots in DT, RF, and KNN\n",
    "classifiers. The data points featured are 200 rows sampled from the more than 18000 rows of\n",
    "the initial dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27862b9c-2c90-43bb-9c9d-22456d86167b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Continuation of Lab 3 - Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abfde5-61f7-4d0e-8126-d33ace707ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Organizing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee2f64-3ab4-43b7-a99f-82ed9c9316f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a new dataframe with 3 or more features (+ y)\n",
    "\n",
    "# Lets see the previous dataframe again to select new features to include\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135e9b3-91b7-4933-a040-5b7662b571c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add the \"Total Bags\" feature\n",
    "df_lab4 = pd.DataFrame({\n",
    "                        \"x1\": df.iloc[:, 0],\n",
    "                        \"x2\": df.iloc[:, 1],\n",
    "                        \"x3\": df.iloc[:, 5], # new feature\n",
    "                        \"y\": df.iloc[:, 9] # class\n",
    "                        })\n",
    "df_lab4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7283a-f539-41f9-8633-3b7bdca8ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a new dataframe with 3 features and a target variable to run the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796b26d-ef62-410b-bd9a-458a9777aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fe791-2c72-498c-9e39-3be2a330e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class is category and has numerical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f5ce3-6c64-4702-bc2d-f9cdecbe2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of values in the feature 'class':\", df_lab4[\"y\"].unique(), \"and dtype=\",df_lab4[\"y\"].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d293c3c-ede9-4ff2-ab81-d80728ad3577",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handling Missing Values and Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7fe5b-aba9-43e6-81f4-c068c2e9d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values\n",
    "df_lab4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8d532-b44c-4f80-a2f5-0656ae237ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d314a-3d3b-4f22-ac15-7f9750480258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df9f44-8346-49b3-92b6-f9dd5c97db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee5eea-56de-40da-b9d1-0efead49a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4[\"y\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260c7cd-207b-4338-836d-35792ae2bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to be used for the classification task\n",
    "df_lab4.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644654ff-5b06-4a22-bda8-720e18abc294",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing dataframes for Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102332ba-7b47-47ee-a42a-018095e6f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the pandas DataFrame into numerical Numpy arrays, \n",
    "# so that they can be processed by the packages in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd9b71-d60d-4122-b7e2-08b9b968df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all types to int\n",
    "df_lab4 = df_lab4.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e613d-0de8-4068-a06f-b35c9bb5489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941b276-f579-48d2-8536-179f17cab1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbad11-605c-467a-be9f-f1ce6b904c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features X and the target variable y\n",
    "df_X = df_lab4.drop([\"y\"], axis=1)\n",
    "df_y = df_lab4[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af0957-a8fd-432d-9500-1a7667a54c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we need transform from Pandas DataFrame to numerical Arrays, and store the column names\n",
    "df_X = df_X.values\n",
    "df_y = df_y.values\n",
    "\n",
    "df_colnames = df_lab4.columns.values\n",
    "print(df_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421faca-ffc5-4506-8d53-37186483e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_X)\n",
    "type(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca8b04-d095-4fae-a028-344233958e68",
   "metadata": {},
   "source": [
    "### Final feature matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd8dd9-499d-45b0-882c-232ead7e3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d11f7-5c5a-43f1-88ff-b3acd78620c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Final target array  ùê≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f913d-9263-47b6-89ac-7cbb08ba07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1838bd-e82d-47d2-b66d-d0897e0ebf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2ccc5-f86a-4c29-a6ef-9e9b0fbcad48",
   "metadata": {},
   "source": [
    "### Single train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99aa75-915b-4be5-8506-2b9532a5be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168abe2-b2cd-469d-8aab-c3ed684e6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_results = confusion_matrix(y_test, y_predicted)\n",
    "cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d2e8b-1d6a-4e17-a954-75967e264022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual representation of the same Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm_results).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a2f9f-05d5-43c1-8d72-cd8af4e6ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "CV_indices = kf.split(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5884a-c3ab-42ee-938a-fdc9e1b47df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in CV_indices:\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd74930-1d24-4e44-a4c8-4549947e083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a574de-1201-4f01-9d9c-a4c6c2ae7e1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experimental evaluation of best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44699d4e-6238-44ff-8d19-5c2a0907af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply the classifiers on the normalized dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_X_norm = scaler.fit_transform(df_X)\n",
    "\n",
    "print(f\"data_X min. value: {df_X_norm.min()}, max. value: {df_X_norm.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c3068-0717-428d-9429-75ad261eb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply my own version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade233dd-6cdd-4a56-9965-81b0b7835a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "MODELS_TO_TEST = {\n",
    "    \"RF_10\": RandomForestClassifier(n_estimators=5, max_depth=10),\n",
    "    \"DT\" :  DecisionTreeClassifier(max_depth=10),\n",
    "    \"KNN\" : KNeighborsClassifier(n_neighbors=2)\n",
    "}\n",
    "\n",
    "# Define the number of splits \n",
    "NUMBER_OF_SPLITS = 10\n",
    "\n",
    "# Scoring metrics\n",
    "SCORING_METRICS = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"] # Metrics of interest\n",
    "\n",
    "# Create empty DataFrame to populate  the name of the classifier and the six values returned from `cross_validate()`\n",
    "results_evaluation = pd.DataFrame({\n",
    "                                    \"classifier_name\":[],\n",
    "                                    \"fit_time\": [],\n",
    "                                    \"score_time\": [],\n",
    "                                    \"test_accuracy\": [],\n",
    "                                    \"test_precision_macro\": [],\n",
    "                                    \"test_recall_macro\": [],\n",
    "                                    \"test_f1_macro\": [],\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5628a13-6b26-4c79-8e4c-0e919dd3de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ITERATION FOR THE EXPERIMENT\n",
    "\n",
    "for name, classifier in MODELS_TO_TEST.items():\n",
    "    \n",
    "    print(f\"Currently training the classifier {name}.\")\n",
    "\n",
    "    # Get the evaluation metrics per fold after cross-validation\n",
    "    # Note that we are passing the normalized array `df_X_norm` to all classifiers\n",
    "    scores_cv = cross_validate(classifier, df_X_norm, df_y, cv=NUMBER_OF_SPLITS, scoring=SCORING_METRICS)\n",
    "\n",
    "    # Average the scores among folds\n",
    "    dict_this_result = {\n",
    "                    \"classifier_name\":[name],\n",
    "                    }\n",
    "    # Populate the dictionary with the results of the cross-validation\n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_this_result[metric_name] = [ scores_cv[metric_name].mean() ]\n",
    "\n",
    "    #### Generate the results to populate the pandas.DataFrame\n",
    "    this_result = pd.DataFrame(dict_this_result)\n",
    "\n",
    "    # Append to the main dataframe with the results \n",
    "    results_evaluation = pd.concat([results_evaluation, this_result], ignore_index=True)\n",
    "\n",
    "print(\"The experimental setup has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64241b5a-b1bf-4a01-8ef7-b9d8414f1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9f1e1-1d9a-4cb5-8ca8-6359b9af7b9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216a461-d914-4d8d-9935-fbd4c18f9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the file in the indicated path\n",
    "file_name = \"results_timing.csv\"\n",
    "results_evaluation.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cd6b5-82a5-4f7e-8f55-d01a293a0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training time (fit_time) and prediction time (score_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec408d-9c87-490e-a70c-574f3e25a156",
   "metadata": {},
   "source": [
    "### Which was the fastest/slowest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3014b-9789-4c91-b2f7-69af888976c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time_classifier = results_evaluation.groupby(by=[\"classifier_name\"]).mean()\n",
    "average_time_classifier.drop([\"test_accuracy\", \"test_precision_macro\", \"test_recall_macro\", \"test_f1_macro\"],axis=1,inplace=True) # Delete unnecessary features\n",
    "average_time_classifier[\"total_time\"] = average_time_classifier[\"fit_time\"] + average_time_classifier[\"score_time\"] # Create new features\n",
    "average_time_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a21c7-3836-479d-b7c4-4b3173ce5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time_classifier.plot.barh()\n",
    "plt.title(\"Average time per classifier among dataset\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a35875-cb85-430e-8296-1388204addb4",
   "metadata": {},
   "source": [
    "RF slowest. DT fastest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7c190-f472-41db-9684-9c9c2f180723",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Which classification model seems to perform better in your data? Would you deploy it in a real-life task? Why or why not?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48125c6e-0574-4c68-8adb-8a15a1f1a524",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The classification model that performs better on my data is the Decision Tree (DT) classifier. It is faster than the KNN classifier and performs almost 70% better than the Random Forest classifier (which is also the worst-performing classifer).  \n",
    "In this case I could employ the KNN classifier because the difference in performance compared to DT isn't that great and KNN performs adequate in small datasets such as this one. For much larger ones I would prefer to use DT compared to KNN due to KNN's large computational cost.  \n",
    "Generally, DT is faster than KNN but DT can be prone to outliers. If total time was irrelevant, and the aim was quality of results, Random Forest would be my personal choice as it is a more robust and accurate version of DT that isn't prone to overfitting.  \n",
    "Important to note is whether the y is consisted of continuous or discrete variables as this changes which classifier is more ideal. In our case the y target variable is consisted of discrete variables and as a result I would choose the DT classifier for a similar real-life task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaeee3c-04c2-409a-81b9-49b099c3cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Which has the best F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1510018-c821-412f-8615-1f4175c22a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_classifier = results_evaluation.groupby(by=[\"classifier_name\"]).mean()\n",
    "accuracy_classifier.drop([\"test_accuracy\", \"fit_time\", \"score_time\", \"test_precision_macro\", \"test_recall_macro\"],axis=1,inplace=True) # Delete unnecessary features\n",
    "#accuracy_classifier[\"total_time\"] = average_time_classifier[\"fit_time\"] + average_time_classifier[\"score_time\"] # Create new features\n",
    "accuracy_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5a367-0497-4f97-b12d-7bb964bfa241",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_classifier.plot.barh()\n",
    "plt.title(\"Macro-F1 score per classifier\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7ab83-f76c-4ff0-8106-bb064fb74e38",
   "metadata": {},
   "source": [
    "The F1 score is a good measure of evaluating model performance. The KNN classifier has performed the best (note that in terms of execution time, KNN perform the worst out of all three classifiers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398ad18-64dd-474f-ad57-8088767dfebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d677a49-7104-44aa-9204-dae9ee0a059c",
   "metadata": {},
   "source": [
    "So far you chose a handful of classifiers with predefined hyperparameters. Describe briefly how do you think you can determine experimentally which hyperparameter performs better for a given classifier? \n",
    "\n",
    "Chosing which hyperparameters to tune can directly affect the performance of a classifier and metrics such as accuracy and the F1 score. It is important to have a close look at the numerical analysis or the \"results_evaluation\" table after each change of the hyperparamaters and then reflect on whether the score has been improved or not. Visualizations on the results table can help us see if the changes made have affected positively or negatively the performance of the classifiers.  \n",
    "If there are mutliple dimensions or many features in our dataset it is more appropriate to consider the numerical analysis of the results_evaluation table to determine areas of improvement and potential tuning of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b621ee4-2bba-4d13-b35b-d5ed9167ec58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
